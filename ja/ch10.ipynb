{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "ADPET68xjlzr",
        "tags": []
      },
      "source": [
        "# 第10章: 事前学習済み言語モデル（GPT型）\n",
        "\n",
        "本章では、GPT型（Transformerのデコーダ型）の事前学習済みモデルを利用して、言語生成、評判分析器（ポジネガ分類器）の構築、ファインチューニング、強化学習などに取り組む。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "C1xKmMckti92",
        "tags": []
      },
      "source": [
        "## 90. 次単語予測\n",
        "\n",
        "“The movie was full of\"に続くトークン（トークン列ではなく一つのトークンであることに注意せよ）として適切なもの上位10個と、その確率（尤度）を求めよ。ただし、言語モデルへのプロンプトがどのようなトークン列に変換されたか、確認せよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "def get_next_token_predictions(prompt_text: str, model_name: str = \"gpt2\", top_k: int = 10):\n",
        "    \"\"\"\n",
        "    指定されたプロンプトに続く次のトークンの上位K個とその確率を予測します。\n",
        "    また、プロンプトがどのようにトークン化されたかを表示します。\n",
        "\n",
        "    Args:\n",
        "        prompt_text (str): 入力プロンプト文字列。\n",
        "        model_name (str, optional): 使用する事前学習済みモデルの名前。\n",
        "                                     デフォルトは \"gpt2\"。\n",
        "        top_k (int, optional): 取得する上位トークンの数。デフォルトは 10。\n",
        "\n",
        "    Returns:\n",
        "        list: 予測されたトークンとその確率のリスト。\n",
        "              各要素は (トークン文字列, 確率) のタプル。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. モデルとトークナイザーのロード\n",
        "        print(f\"Loading model and tokenizer for '{model_name}'...\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "        # モデルを評価モードに設定 (勾配計算をオフにするなど)\n",
        "        model.eval()\n",
        "\n",
        "        # 2. プロンプトのトークン化\n",
        "        print(f\"\\n--- Tokenizing Prompt: \\\"{prompt_text}\\\" ---\")\n",
        "        # トークナイザーによっては、プロンプトの先頭にスペースが必要な場合があるため、\n",
        "        # GPT-2のようなモデルではそのままで良いが、モデルに応じて調整することも考慮\n",
        "        inputs = tokenizer(prompt_text, return_tensors=\"pt\")\n",
        "        input_ids = inputs[\"input_ids\"]\n",
        "\n",
        "        print(f\"Input IDs: {input_ids.tolist()[0]}\")\n",
        "        tokens = [tokenizer.decode([token_id]) for token_id in input_ids[0].tolist()]\n",
        "        # トークンによっては、デコード時に不要なスペースが含まれることがあるため、必要に応じて調整\n",
        "        # 例: tokens = [tokenizer.convert_ids_to_tokens(token_id) for token_id in input_ids[0].tolist()]\n",
        "        print(f\"Tokens: {tokens}\")\n",
        "        print(\"--------------------------------------\")\n",
        "\n",
        "        # 3. 次のトークンの予測\n",
        "        with torch.no_grad(): # 勾配計算を行わないコンテキスト\n",
        "            outputs = model(input_ids)\n",
        "            # outputs.logits の形状は (batch_size, sequence_length, vocab_size)\n",
        "            # 次のトークンの予測なので、最後のトークン位置のlogitsを使用\n",
        "            next_token_logits = outputs.logits[0, -1, :]\n",
        "\n",
        "        # 4. Logitsを確率に変換 (Softmax)\n",
        "        probabilities = torch.softmax(next_token_logits, dim=-1)\n",
        "\n",
        "        # 5. 上位K個のトークンとその確率を取得\n",
        "        top_k_probabilities, top_k_indices = torch.topk(probabilities, top_k)\n",
        "\n",
        "        results = []\n",
        "        print(f\"\\n--- Top {top_k} next token predictions for \\\"{prompt_text}\\\" ---\")\n",
        "        for i in range(top_k):\n",
        "            token_id = top_k_indices[i].item()\n",
        "            token_probability = top_k_probabilities[i].item()\n",
        "            # token_idを文字列にデコード\n",
        "            # decodeメソッドはリスト形式のIDも受け付ける\n",
        "            token_string = tokenizer.decode([token_id])\n",
        "            results.append((token_string, token_probability))\n",
        "            print(f\"{i+1}. Token: \\\"{token_string}\\\" (ID: {token_id}), Probability: {token_probability:.6f}\")\n",
        "        print(\"----------------------------------------------------\")\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return []\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    prompt = \"The movie was full of\"\n",
        "    # GPT-2モデルを使用します。他のモデル (例: \"gpt2-medium\", \"gpt2-large\", \"EleutherAI/gpt-neo-1.3B\" など) も試せます。\n",
        "    # 大きなモデルほど、より高品質な予測が期待できますが、計算リソースも多く必要とします。\n",
        "    predicted_tokens = get_next_token_predictions(prompt, model_name=\"gpt2\", top_k=10)\n",
        "\n",
        "    # (オプション) 他のGPT系モデルを試す場合\n",
        "    # print(\"\\nTrying with gpt2-medium (may take longer to download/run):\")\n",
        "    # predicted_tokens_medium = get_next_token_predictions(prompt, model_name=\"gpt2-medium\", top_k=10)"
      ],
      "metadata": {
        "id": "CSxBKq2GiBE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "s1RhOldA0meh",
        "tags": []
      },
      "source": [
        "## 91. 続きのテキストの予測\n",
        "\n",
        "“The movie was full of\"に続くテキストを複数予測せよ。このとき、デコーディングの方法や温度パラメータ（temperature）を変えながら、予測される複数のテキストの変化を観察せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "7ZFadg6B8VdA",
        "tags": []
      },
      "source": [
        "## 92. 予測されたテキストの確率を計算\n",
        "\n",
        "“The movie was full of\"に続くテキストを予測し、生成された各単語の尤度を表示せよ（生成されるテキストが長いと出力が読みにくくなるので、適当な長さで生成を打ち切るとよい）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "FvNCTMj6OegF",
        "tags": []
      },
      "source": [
        "## 93. パープレキシティ\n",
        "\n",
        "適当な文を準備して、事前学習済み言語モデルでパープレキシティを測定せよ。例えば、\n",
        "\n",
        "+ The movie was full of surprises\n",
        "+ The movies were full of surprises\n",
        "+ The movie were full of surprises\n",
        "+ The movies was full of surprises\n",
        "\n",
        "の4文に対して、パープレキシティを測定して観察せよ（最後の2つの文は故意に文法的な間違いを入れた）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-7fB-n9suYg"
      },
      "source": [
        "## 94. チャットテンプレート\n",
        "\n",
        "\"What do you call a sweet eaten after dinner?\"という問いかけに対する応答を生成するため、チャットテンプレートを適用し、言語モデルに与えるべきプロンプトを作成せよ。また、そのプロンプトに対する応答を生成し、表示せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "PT-bk0XWIZ2E",
        "tags": []
      },
      "source": [
        "## 95. マルチターンのチャット\n",
        "\n",
        "問題94で生成された応答に対して、追加で\"Please give me the plural form of the word with its spelling in reverse order.\"と問いかけたときの応答を生成・表示せよ。また、その時に言語モデルに与えるプロンプトを確認せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "qH0YortL0afd",
        "tags": []
      },
      "source": [
        "## 96. プロンプトによる感情分析\n",
        "\n",
        "事前学習済み言語モデルで感情分析を行いたい。テキストを含むプロンプトを事前学習済み言語モデルに与え、（ファインチューニングは行わずに）テキストのポジネガを予測するという戦略で、[SST-2](https://dl.fbaipublicfiles.com/glue/data/SST-2.zip)の開発データにおける正解率を測定せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "giA6FivrKaSf",
        "tags": []
      },
      "source": [
        "## 97. 埋め込みに基づく感情分析\n",
        "\n",
        "事前学習済み言語モデルでテキストをベクトルで表現（エンコード）し、そのベクトルにフィードフォワード層を通すことで極性ラベルを予測するモデルを学習せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "UnREZD3nTWUr",
        "tags": []
      },
      "source": [
        "## 98. ファインチューニング\n",
        "\n",
        "問題96のプロンプトに対して、正解の感情ラベルをテキストの応答として返すように事前学習済みモデルをファインチューニングせよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "4f0St5Ce0l34",
        "tags": []
      },
      "source": [
        "## 99. 選好チューニング\n",
        "\n",
        "問題96のプロンプトに対して、正解の感情ラベルを含むテキストを望ましい応答、間違った感情ラベルを含むテキストを望ましくない応答として、事前学習済み言語モデルを選好チューニング (preference tuning) を実施せよ。選好チューニングのアルゴリズムとしては、近傍方策最適化 (PPO: Proximal Policy Optimization) や直接選好最適化 (DPO: Direct Preference Optimization) などが考えられる。\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}